{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3281cd01",
   "metadata": {},
   "source": [
    "## Defining a class to analyze a document \n",
    "\n",
    "\n",
    " - Defining a new class called `Analyzer` as follows: \n",
    " \n",
    "    - It has two attributes:\n",
    "        - `text`: store the document text \n",
    "        - `vocab`: a dictionary to store the count of each token  \n",
    "  \n",
    "    - It has an `__init__` function which \n",
    "       - takes `doc`, a document (i.e. a string) as an input, and save `doc` into `text` attribute\n",
    "       - calls the `tokenize` function that you defined in Q1 with `doc` as the input, and save the returned dictionary to `vocab` attribute \n",
    "\n",
    "    - It has a function named `sentiment(postives, negatives)` which \n",
    "        - calls `get_sentiment` function you defined in Q2 to analyze the `text` attribute with the supplied `positives` and `negatives` word lists\n",
    "        - returns an overall sentiment score\n",
    "\n",
    "    - It has a function named `topN` which \n",
    "        - takes a number `N` as an input\n",
    "        - finds the most frequent `N` words and their counts in the document\n",
    "        - returns the top `N` words and their counts as a list of tuples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bf81731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer(object):\n",
    "\n",
    "    \n",
    "    # add your code here\n",
    "    def __init__(self,text):\n",
    "        self.text = text\n",
    "        t = tokenize(self.text)\n",
    "        self.vocab = t\n",
    "        \n",
    "    def sentiment(self,positives,negatives):\n",
    "        score = get_sentiment(self.text, positives, negatives)[-1]\n",
    "        return score\n",
    "    \n",
    "    def topN (self,N):\n",
    "        \n",
    "        i = self.vocab.items()\n",
    "        \n",
    "        #To sort the dictionary according to keys\n",
    "        t = {(value,key) for key,value in i}                #Swapping key and value elements \n",
    "        t_sorted = sorted(t)                                #Sorting the dictionary in terms of keys\n",
    "        final_t = [(value,key) for key,value in t_sorted]   #Swapping key and value elements\n",
    "        \n",
    "        T = final_t[::-1]                                   #Reversing the list (desc. order of values)\n",
    "        \n",
    "        T = T[:N]                                           #Return the first N values\n",
    "      \n",
    "        return T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a981f4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: \n",
      " {'what': 1, 'investors': 1, 'don’t': 1, 'like': 1, 'is': 2, 'uncertainty': 1, 'said': 1, 'jason': 1, 'draho': 1, 'head': 1, 'of': 4, 'asset': 1, 'allocation': 1, 'americas': 1, 'at': 3, 'ubs': 1, 'global': 1, 'wealth': 1, 'management': 1, 'in': 4, 'phone': 1, 'interview': 1, 'pointing': 1, 'to': 1, 'selloff': 1, 'that’s': 1, 'left': 1, 'few': 1, 'corners': 1, 'financial': 1, 'markets': 1, 'unscathed': 1, 'january': 1, 'even': 1, 'with': 1, 'sharp': 1, 'rally': 1, 'late': 1, 'friday': 1, 'the': 2, 'interest': 1, 'rate-sensitive': 1, 'nasdaq': 1, 'composite': 1, 'index': 2, 'comp': 1, '3.13': 1, 'remained': 1, 'correction': 1, 'territory': 1, 'defined': 1, 'as': 1, 'fall': 1, 'least': 2, '10': 1, 'from': 2, 'its': 2, 'most': 1, 'recent': 1, 'record': 1, 'close': 1, 'worse': 1, 'russell': 1, '2000': 1, 'small-capitalization': 1, 'stocks': 1, 'rut': 1, '1.93': 1, 'bear': 1, 'market': 1, 'down': 1, '20': 1, 'nov': 1, 'peak': 1} \n",
      "\n",
      "Sentiment:  -1 \n",
      "\n",
      "Top 3 words:  [('of', 4), ('in', 4), ('at', 3)]\n"
     ]
    }
   ],
   "source": [
    "# Code to test your class\n",
    "\n",
    "positives = open(\"positive-words.txt\").read().split()\n",
    "negatives = open(\"negative-words.txt\").read().split()\n",
    "\n",
    "\n",
    "doc ='''\"What investors don’t like is uncertainty,\" said Jason Draho, \n",
    "        head of asset allocation Americas at UBS Global Wealth Management, \n",
    "        in a phone interview, pointing to a selloff that’s left \n",
    "        few corners of financial markets unscathed in January.\n",
    "\n",
    "        Even with a sharp rally late Friday, the interest rate-sensitive Nasdaq \n",
    "        Composite Index COMP, +3.13% remained in correction territory, defined \n",
    "        as a fall of at least 10% from its most recent record close. Worse, \n",
    "        the Russell 2000 index of small-capitalization stocks RUT, +1.93% is \n",
    "        in a bear market, down at least 20% from its Nov. 8 peak.\n",
    "    '''\n",
    "analyzer = Analyzer(doc)\n",
    "\n",
    "print(\"Vocabulary: \\n\", analyzer.vocab, \"\\n\")\n",
    "print(\"Sentiment: \", analyzer.sentiment(positives, negatives), \"\\n\")\n",
    "print(\"Top 3 words: \",analyzer.topN(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
